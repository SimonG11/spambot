{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6ba13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cde2aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the .names file\n",
    "spambase_names_path = 'spambase.names'\n",
    "\n",
    "# Function to read and extract feature names from the .names file\n",
    "def extract_feature_names(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Skipping the first 33 lines and start reading from line 34\n",
    "        lines = file.readlines()[33:]\n",
    "    # Extract feature names from the file content\n",
    "    feature_names = []\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            name = line.split(':')[0]\n",
    "            feature_names.append(name)\n",
    "    return feature_names\n",
    "\n",
    "# Adding names\n",
    "feature_names = extract_feature_names(spambase_names_path)\n",
    "feature_names.append('is_spam')  # Adding the class label since it is not defined as the last column name\n",
    "\n",
    "# Load the dataset with names\n",
    "spambase_data_path = 'spambase.data'\n",
    "data = pd.read_csv(spambase_data_path, names=feature_names)\n",
    "\n",
    "# Separate X and y\n",
    "X = data.drop('is_spam', axis=1)\n",
    "y = data['is_spam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bd117b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61b30555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initianlizing classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_features='sqrt'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f180a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold with 10 splits\n",
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cb130d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to compute\n",
    "scoring = ['accuracy', 'f1']\n",
    "\n",
    "# Dictionary to store all results\n",
    "results = {'Accuracy': {name: [] for name in classifiers.keys()},\n",
    "           'F-Measure': {name: [] for name in classifiers.keys()},\n",
    "           'Training Time': {name: [] for name in classifiers.keys()}}\n",
    "\n",
    "# Perform cross-validation for each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    cv_results = cross_validate(clf, X_train, y_train, cv=skf, scoring=scoring, return_train_score=False, n_jobs=-1)\n",
    "\n",
    "    results['Accuracy'][name] = cv_results['test_accuracy']\n",
    "    results['F-Measure'][name] = cv_results['test_f1']\n",
    "    results['Training Time'][name] = cv_results['fit_time']\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "for metric in results:\n",
    "    results[metric] = pd.DataFrame(results[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e698227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation for each classifier in each metric\n",
    "final_results = {}\n",
    "for metric, df in results.items():\n",
    "    means = df.mean(axis=0).rename('Mean')\n",
    "    stds = df.std(axis=0).rename('Std')\n",
    "    final_results[metric] = pd.concat([means, stds], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7da510cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Ranks:\n",
      "-------------------------------------------------------\n",
      "    Random Forest  Naive Bayes  Gradient Boosting\n",
      "-------------------------------------------------------\n",
      "0   0.970109  0.880435  0.970109\n",
      "1   0.975543  0.804348  0.970109\n",
      "2   0.948370  0.796196  0.951087\n",
      "3   0.961957  0.823370  0.956522\n",
      "4   0.964674  0.807065  0.951087\n",
      "5   0.942935  0.815217  0.940217\n",
      "6   0.937500  0.807065  0.926630\n",
      "7   0.945652  0.826087  0.923913\n",
      "8   0.945652  0.823370  0.942935\n",
      "9   0.951087  0.820652  0.932065\n",
      "-------------------------------------------------------\n",
      "mean 0.954348  0.820380  0.946467\n",
      "std 0.012797  0.023286  0.016407\n",
      "-------------------------------------------------------\n",
      "\n",
      "F-Measure without Ranks:\n",
      "-------------------------------------------------------\n",
      "    Random Forest  Naive Bayes  Gradient Boosting\n",
      "-------------------------------------------------------\n",
      "0   0.962199  0.865031  0.962199\n",
      "1   0.968858  0.796610  0.961404\n",
      "2   0.932384  0.787535  0.937063\n",
      "3   0.951049  0.811594  0.944056\n",
      "4   0.955631  0.791789  0.937063\n",
      "5   0.927835  0.806818  0.924658\n",
      "6   0.919861  0.793003  0.906574\n",
      "7   0.928058  0.809524  0.898551\n",
      "8   0.929577  0.807122  0.926316\n",
      "9   0.936620  0.805882  0.911661\n",
      "-------------------------------------------------------\n",
      "mean 0.941207  0.807491  0.930954\n",
      "std 0.016838  0.021879  0.021673\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training Time without Ranks:\n",
      "-------------------------------------------------------\n",
      "    Random Forest  Naive Bayes  Gradient Boosting\n",
      "-------------------------------------------------------\n",
      "0   0.437749  0.003549  1.063334\n",
      "1   0.429783  0.003289  1.086039\n",
      "2   0.442938  0.002708  1.067171\n",
      "3   0.426824  0.002633  1.066684\n",
      "4   0.414745  0.002966  1.064586\n",
      "5   0.455667  0.002509  1.062121\n",
      "6   0.411827  0.003008  1.055917\n",
      "7   0.430927  0.002431  1.063645\n",
      "8   0.313980  0.002287  0.820255\n",
      "9   0.307783  0.002213  0.817778\n",
      "-------------------------------------------------------\n",
      "mean 0.407222  0.002759  1.016753\n",
      "std 0.052355  0.000437  0.104502\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the results in table 12.4 format\n",
    "for metric in results:\n",
    "    print(f\"{metric} without Ranks:\")\n",
    "    print('-'*55)\n",
    "    \n",
    "    # Print the classifier names\n",
    "    classifier_names = results[metric].columns\n",
    "    print('   ', '  '.join(classifier_names))\n",
    "    print('-'*55)\n",
    "    \n",
    "    # Print each row of data (for each fold)\n",
    "    for index in range(len(results[metric])):\n",
    "        row_data = [results[metric][classifier].iloc[index] for classifier in classifier_names]\n",
    "        print(f\"{index:<3}\", '  '.join(f\"{val:.6f}\" for val in row_data))\n",
    "    \n",
    "    print('-'*55)\n",
    "\n",
    "    # Calculate and print mean and std for each classifier\n",
    "    means = results[metric].mean()\n",
    "    stds = results[metric].std()\n",
    "\n",
    "    print(\"mean\", '  '.join(f\"{means[name]:.6f}\" for name in classifier_names))\n",
    "    print(\"std\", '  '.join(f\"{stds[name]:.6f}\" for name in classifier_names))\n",
    "    print('-'*55)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5eb9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the results DataFrame with ranks for each fold\n",
    "for metric, df in results.items():\n",
    "    ascending = True if metric == 'Training Time' else False\n",
    "    ranks = df.rank(axis=1, ascending=ascending)\n",
    "    \n",
    "    ranked_df = df.copy()\n",
    "    for col in ranked_df.columns:\n",
    "        ranked_df[col] = ranked_df[col].round(6).astype(str) + \" (\" + ranks[col].astype(int).astype(str) + \")\"\n",
    "    \n",
    "    results[metric] = ranked_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96010c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Ranks:\n",
      "-------------------------------------------------------\n",
      "   Random Forest  Naive Bayes  Gradient Boosting\n",
      "-------------------------------------------------------\n",
      "0 0.970109 (1)  0.880435 (3)  0.970109 (1)\n",
      "1 0.975543 (1)  0.804348 (3)  0.970109 (2)\n",
      "2 0.94837 (2)  0.796196 (3)  0.951087 (1)\n",
      "3 0.961957 (1)  0.82337 (3)  0.956522 (2)\n",
      "4 0.964674 (1)  0.807065 (3)  0.951087 (2)\n",
      "5 0.942935 (1)  0.815217 (3)  0.940217 (2)\n",
      "6 0.9375 (1)  0.807065 (3)  0.92663 (2)\n",
      "7 0.945652 (1)  0.826087 (3)  0.923913 (2)\n",
      "8 0.945652 (1)  0.82337 (3)  0.942935 (2)\n",
      "9 0.951087 (1)  0.820652 (3)  0.932065 (2)\n",
      "-------------------------------------------------------\n",
      "Average Rank 1.1  3.0  1.8\n",
      "-------------------------------------------------------\n",
      "\n",
      "F-Measure with Ranks:\n",
      "-------------------------------------------------------\n",
      "   Random Forest  Naive Bayes  Gradient Boosting\n",
      "-------------------------------------------------------\n",
      "0 0.962199 (1)  0.865031 (3)  0.962199 (1)\n",
      "1 0.968858 (1)  0.79661 (3)  0.961404 (2)\n",
      "2 0.932384 (2)  0.787535 (3)  0.937063 (1)\n",
      "3 0.951049 (1)  0.811594 (3)  0.944056 (2)\n",
      "4 0.955631 (1)  0.791789 (3)  0.937063 (2)\n",
      "5 0.927835 (1)  0.806818 (3)  0.924658 (2)\n",
      "6 0.919861 (1)  0.793003 (3)  0.906574 (2)\n",
      "7 0.928058 (1)  0.809524 (3)  0.898551 (2)\n",
      "8 0.929577 (1)  0.807122 (3)  0.926316 (2)\n",
      "9 0.93662 (1)  0.805882 (3)  0.911661 (2)\n",
      "-------------------------------------------------------\n",
      "Average Rank 1.1  3.0  1.8\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training Time with Ranks:\n",
      "-------------------------------------------------------\n",
      "   Random Forest  Naive Bayes  Gradient Boosting\n",
      "-------------------------------------------------------\n",
      "0 0.437749 (2)  0.003549 (1)  1.063334 (3)\n",
      "1 0.429783 (2)  0.003289 (1)  1.086039 (3)\n",
      "2 0.442938 (2)  0.002708 (1)  1.067171 (3)\n",
      "3 0.426824 (2)  0.002633 (1)  1.066684 (3)\n",
      "4 0.414745 (2)  0.002966 (1)  1.064586 (3)\n",
      "5 0.455667 (2)  0.002509 (1)  1.062121 (3)\n",
      "6 0.411827 (2)  0.003008 (1)  1.055917 (3)\n",
      "7 0.430927 (2)  0.002431 (1)  1.063645 (3)\n",
      "8 0.31398 (2)  0.002287 (1)  0.820255 (3)\n",
      "9 0.307783 (2)  0.002213 (1)  0.817778 (3)\n",
      "-------------------------------------------------------\n",
      "Average Rank 2.0  1.0  3.0\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save avg ranks for fridman test\n",
    "average_ranks = {}\n",
    "\n",
    "# # Print the results in table 12.8 format\n",
    "for metric, df in results.items():\n",
    "    print(f\"{metric} with Ranks:\")\n",
    "    print('-'*55)\n",
    "    \n",
    "    # Print the classifier names\n",
    "    classifier_names = df.columns\n",
    "    print('  ', '  '.join(classifier_names))\n",
    "    print('-'*55)\n",
    "    \n",
    "    # Print each row of data with ranks\n",
    "    for index, row in df.iterrows():\n",
    "        formatted_row = [f\"{value}\" for value in row]\n",
    "        print(index, '  '.join(formatted_row))\n",
    "    \n",
    "    print('-'*55)\n",
    "\n",
    "    # Calculate and store the average rank for each classifier\n",
    "    # if you have an older verison of pandas use \"applymap.\" insted of map\n",
    "    avg_ranks = df.map(lambda x: int(x.split('(')[1].replace(')', ''))).mean(axis=0)\n",
    "    average_ranks[metric] = avg_ranks.values\n",
    "\n",
    "    print(\"Average Rank\", '  '.join(f\"{avg_ranks[name]:.1f}\" for name in classifier_names))\n",
    "    print('-'*55)\n",
    "    print()\n",
    "\n",
    "# Make the avg ranks to list\n",
    "avg_ranks_accuracy = list(average_ranks.get('Accuracy', []))\n",
    "avg_ranks_fmeasure = list(average_ranks.get('F-Measure', []))\n",
    "avg_ranks_training_time = list(average_ranks.get('Training Time', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aae1aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman Statistic and Degrees of Freedom for Each Metric:\n",
      "Accuracy: Chi2 = 14.50000000000001, df = 2\n",
      "F-Measure: Chi2 = 14.50000000000001, df = 2\n",
      "Training Time: Chi2 = 20.0, df = 2\n"
     ]
    }
   ],
   "source": [
    "def friedman_statistic(avg_ranks, N, k):\n",
    "    # Calculation of Friedman statistic\n",
    "    sum_of_squares = np.sum(avg_ranks ** 2)\n",
    "    chi2 = (12 * N / (k * (k + 1))) * (sum_of_squares - (k * (k + 1) ** 2 / 4))\n",
    "    degrees_of_freedom = k - 1\n",
    "\n",
    "    return chi2, degrees_of_freedom\n",
    "\n",
    "\n",
    "N = 10  # Number of datasets\n",
    "k = 3   # Number of algorithms\n",
    "\n",
    "# Retrive the avg ranks for each metric\n",
    "avg_ranks_accuracy = np.array(avg_ranks_accuracy) \n",
    "avg_ranks_fmeasure = np.array(avg_ranks_fmeasure)\n",
    "avg_ranks_training_time = np.array(avg_ranks_training_time)\n",
    "\n",
    "# Retrive Friedman statistic for each metric\n",
    "chi2_accuracy, df_accuracy = friedman_statistic(avg_ranks_accuracy, N, k)\n",
    "chi2_fmeasure, df_fmeasure = friedman_statistic(avg_ranks_fmeasure, N, k)\n",
    "chi2_training_time, df_training_time = friedman_statistic(avg_ranks_training_time, N, k)\n",
    "\n",
    "# Print the stats\n",
    "print(\"Friedman Statistic and Degrees of Freedom for Each Metric:\")\n",
    "print(f\"Accuracy: Chi2 = {chi2_accuracy}, df = {df_accuracy}\")\n",
    "print(f\"F-Measure: Chi2 = {chi2_fmeasure}, df = {df_fmeasure}\")\n",
    "print(f\"Training Time: Chi2 = {chi2_training_time}, df = {df_training_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f171797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance and Critical Differences for Each Metric:\n",
      "Accuracy: Significance = True, CD = 1.2199986885238854\n",
      "F-Measure: Significance = True, CD = 1.2199986885238854\n",
      "Training Time: Significance= True, CD = 1.2199986885238854\n"
     ]
    }
   ],
   "source": [
    "def is_significant(chi2_statistic):\n",
    "    # determine if value is significant\n",
    "    critical_value = 7.8\n",
    "    return chi2_statistic > critical_value\n",
    "\n",
    "def nemenyi_critical_difference(N, k, alpha=0.05):\n",
    "    # Critical value q_alpha for the studentized range statistic (to be verified)\n",
    "    q_alpha = 2.728  # Example value\n",
    "    return q_alpha * np.sqrt((k * (k + 1)) / (6 * N))\n",
    "\n",
    "\n",
    "# Check significance for each metric and calculate critical differences if significant\n",
    "significance_accuracy = is_significant(chi2_accuracy)\n",
    "significance_fmeasure = is_significant(chi2_fmeasure)\n",
    "significance_training_time = is_significant(chi2_training_time)\n",
    "\n",
    "# Only retrive the value if significant\n",
    "cd_accuracy = nemenyi_critical_difference(N, k) if significance_accuracy else None\n",
    "cd_fmeasure = nemenyi_critical_difference(N, k) if significance_fmeasure else None\n",
    "cd_training_time = nemenyi_critical_difference(N, k) if significance_training_time else None\n",
    "\n",
    "# Print results\n",
    "print(\"Significance and Critical Differences for Each Metric:\")\n",
    "print(f\"Accuracy: Significance = {significance_accuracy}, CD = {cd_accuracy}\")\n",
    "print(f\"F-Measure: Significance = {significance_fmeasure}, CD = {cd_fmeasure}\")\n",
    "print(f\"Training Time: Significance= {significance_training_time}, CD = {cd_training_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f6b3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance for accuracy :\n",
      "Random Forest and Naive Bayes are significantly differerent\n",
      "\n",
      "Significance for fmeasure :\n",
      "Random Forest and Naive Bayes are significantly differerent\n",
      "\n",
      "Significance for training_time :\n",
      "Naive Bayes and Gradient Boosting are significantly differerent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def significant_difference(rank_lst, cd):\n",
    "    # Retrive indexes where there is significant difference between avg ranks of classifiers.\n",
    "    result = []\n",
    "    for i in range(len(avg_ranks_cd[0])-1):\n",
    "        for j in range(len(rank_lst)):\n",
    "            if abs(rank_lst[i] - rank_lst[j]) > cd and {i, j} not in result:\n",
    "                result.append({i, j})\n",
    "    return result\n",
    "\n",
    "\n",
    "def show(lst):\n",
    "    # Print the sets \n",
    "    for pair in lst:\n",
    "        print(f\"{cls[pair.pop()]} and {cls[pair.pop()]} are significantly differerent\")\n",
    "\n",
    "\n",
    "avg_ranks_with_cd = {\"accuracy\":[avg_ranks_accuracy, cd_accuracy],\n",
    "                     \"fmeasure\": [avg_ranks_fmeasure, cd_fmeasure], \n",
    "                     \"training_time\":[avg_ranks_training_time, cd_training_time]}\n",
    "\n",
    "cls = [\"Random Forest\",\n",
    "       \"Naive Bayes\", \n",
    "       \"Gradient Boosting\"]\n",
    "\n",
    "for measure, avg_ranks_cd in avg_ranks_with_cd.items():\n",
    "    # Loop through the messures and check for differences.\n",
    "    print(\"Significance for\", measure, \":\")\n",
    "    if avg_ranks_cd[1]:\n",
    "        result = significant_difference(avg_ranks_cd[0], avg_ranks_cd[1])\n",
    "        show(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac51e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd2220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac31cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783ff5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cefa94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
